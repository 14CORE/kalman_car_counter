\documentclass[draft]{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{mathtools}
%\documentstyle[nips13submit_09,times,art10]{article} % For LaTeX 2.09


% % % % % % % % % % % % % % % % % % % % % % % % %
% Justin additions							    %
%===============================================%
% Remove the [draft] on line 1 to hide my shit  %
% % % % % % % % % % % % % % % % % % % % % % % % %

\usepackage{ifdraft}
\usepackage{hyperref}

\newcommand{\justin}[1]{\ifdraft{\textcolor{red}{\textbf{#1}}}{}}

% % % % % % % % % % % % % % % % % % % % % % % % %
% End Justin additions							%
% % % % % % % % % % % % % % % % % % % % % % % % %

\title{Traffic Counting with Kalman Filters}


\author{
Anthony M Lozano\\
Department of Computer Science\\
Georgia Institute of Technology\\
\texttt{amlozano1@gmail.com} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\begin{abstract}
Counting vehicles is an important function for traffic video data analysis. This paper examines an approach of using a Shi-Tomasi corner detector with a Lucas Kanade Optical flow pyramid to create data measurements. After clustering tracked data measurements, a Kalman Filter is used to process the data in order to finally determine if a vehicle passes through the video. Our implementation of this method shows some success, but needs refinement.
\end{abstract}

\section{Background/Problem Description}
\label{sec:background}

\justin{labels should be unique so you can reference them later eg Background is in Section \ref{sec:background}. (look at the source).}

Good traffic data is an important for many users.  Civil Engineers need traffic data to design, construct and maintain roadways.  Policy makers use it to allocate funding for such projects, and business owners may be interested in such data when deciding where to start a new business.  The data can even be used to estimate environmental impact of roadways and perform other similar estimations.

The data is useful, but existing methods for capturing the data seem more expensive and or cumbersome then they ought to be. \justin{Previous sentence should probably be more concrete - they don't seem that way, they \textit{are} that way.}  The chief problems of current solutions are portability, setup time, or need for humans to process the data.  \justin{and need for humans...}  Portability might not be an issue for areas where traffic data will need to be collected permanently, but usually agencies want a system that can move easily to take measurements from many sites. \justin{While portability is not an issue in more permanent sensor deployments, there lacks a temporary solution for ad-hoc data collection}.  Some examples of not so portable \justin{less portable sounds better to me} systems include inductive loop sensors installed into the roadway itself, or the TRAX Stealth Stud, which is another device that needs to be installed into the pavement.  Installing these devices requires closing the road, which is not ideal as many urban areas will suffer major disruption from even a relatively short road closure. \justin{...is not ideal in situations where even a relatively short road closure may cause major disruptions, such as urban areas.}  Pneumatic loop sensors, which look like small black tubes that are laid perpendicularly over the road, are an effective solution, but some jurisdictions in the United States require that workers close the road when they are putting these up anyway for safety reasons. \justin{you have a wicked comma splice back there son.}  Other systems use a camera and a human to count the cars going by, but while this produces very accurate data it is time consuming. \justin{Other systems use a human-operated camera to track vehicles as they pass, producing extremely accurate data with the caveat of being labor intensive and time consuming.}  Humans need to check and recheck their counts, and sometimes vehicle classifications are subjective. \justin{This sentence lacks context. State that they are problems.}  These systems and devices are also expensive, costing thousands of dollars for a single unit or many man hours of labor. \justin{to purchase and operate a single unit.}

This paper attempts to create a software analysis tool that can perform one of the most basic tasks for traffic data collection; counting how many cars have gone in a particular direction in a video. This software tool would enable anyone with a camera and a decent vantage point can collect and contribute to traffic data collection efforts. 

\section{Hypothesis and Project Approach}
\label{sec:hypothesis}

Our hypothesis is that computer vision techniques for tracking motion in video combined with a Kalman Filter should be able to track vehicles and plot their movements. The software will then record the starting and ending points of each successfully tracked vehicle, thus establishing counts for each origin and destination. \justin{consider removing the "our hypothesis" and just state that Motion tracking computer vision techniques combined with...can track vehicles. Don't say should be - be concrete.}


\section{Implementation Details}
\label{sec:implementation}

The Kalman Car Counter program will need to perform six major tasks to enable counting of vehicles. \justin{"count vehicles." sounds too weird.} These tasks are background subtraction (or foreground detection), feature detection, optical flow estimation, optical flow clustering, and finally Kalman Filtering.

\subsection{Background Subtraction}
\label{subsec:back_subract}

Background subtraction is the process of removing noise and unmoving sections of an image.  The Kalman Car Counter uses the simple process of frame differencing to remove the background for speed. \justin{maybe comparison of different frames? frame deltas? just an idea. then you can use $\Delta$ which is fun.} Frame difference at a time $t$ can be calculated as 
$ D(t+1) = V(x,y,t+1) - V(x,y,t) $ for each pixel $(x,y)$~\cite{Birgi09}.
This calculation will allow the subsequent algorithms to focus solely on areas of the video that contain motion, helping isolate vehicles and removing image noise.

\subsection{Feature Detection}
\label{subsec:feature_detec}

Feature detection is the process of finding good features of an image for tracking. For vehicle tracking, Shi-Tomasi corner detection is a solid algorithm choice that expands on standard Harris corner detection. \justin{and will (or something - combine these into one coherant thought)} It will allow us to zero in on the "corners" of vehicles. Briefly, the algorithm works as follows: If we can assume the time between frames is small, we can describe the changes between them as image motion. If we take a patch of an image defined by $(u,v)$ and shift it by $(x,y)$, the weighted sum of squared differences between the two patches, $S$ is given by \\*

{\centering
$ S(x,y) = \sum\limits_{u}\sum\limits_{v}w(u,v)(I(u+x, v+y) - I(u,v))^2$\linebreak\newline\\*}
$I(u+x,v+y)$ can be approximated bu a Taylor expansion with $I_x,$ and $I_y$ being the partial derivatives of $I$ such that:\\*

{\centering
$I(u+x,v+y)) \approx I(u,v) (I_x(u,v) x+I_y(u,v) y)^2$\linebreak\newline\\*}
which produces the approximation\\*

{\centering
$S(x,y) \approx \sum\limits_{u}\sum\limits_{v}w(u,v) (I_x(u,v) x+I_y(u,v) y)^2$\linebreak\newline\\*}
which in matrix form is\\*

{\centering
$S(x,y) \approx \left(\begin{smallmatrix}
x & y
\end{smallmatrix}\right) A
\left(\begin{smallmatrix}
x\\
y
\end{smallmatrix}\right)$\linebreak\newline\\*}
where $A$ is the structure tensor\\*
\\*

{\centering
$
A = \sum_u \sum_v w(u,v) 
\begin{bmatrix}
I_x^2 & I_x I_y \\
I_x I_y & I_y^2 
\end{bmatrix}
=
\begin{bmatrix}
\langle I_x^2 \rangle & \langle I_x I_y \rangle\\
\langle I_x I_y \rangle & \langle I_y^2 \rangle
\end{bmatrix}$\linebreak\newline\\*}
\justin{Fiddle with the spacing on those to make the top and bottom even - but it looks a lot better centered imo} A corner is then found if $S$ has a large variation in all directions of the vector $\begin{pmatrix} x & y \end{pmatrix}$. Thus, if $A$ has two positive eigenvalues that are large in comparison to other eigenvalues, a corner is found~\cite{tommasini1998making}. The Shi-Tomasi corner detector takes a practical shortcut and only calculates $min(\lambda_1, \lambda_2)$ rather than doing a complete eigenvalue decomposition in the interest of speed and because this is sufficient to find features with great accuracy~\cite{Shi94}.

\subsection{Optical Flow}
Once we have determined what features in the image to track, we actually need to track them. To accomplish this, the Kalman Car Counter will use another well known algorithm, the Lucas-Kanade method. This method assumes that pixels move a small amount between frames, and the movement of the pixels is approximatly the same for all pixels in the neighborhood of a point $p$~\cite{lucas1981iterative}. Therefore, the optical flow equation should hold for all pixels in a window centered at $p$. This means the local velocity of a feature $(V_x,V_y)$ must satisfy the equations:\\*

{\centering
$I_x(q_1) V_x + I_y (q_1) V_y = -I_t(q_1)$\\*
$I_x(q_2) V_x + I_y (q_2) V_y = -I_t(q_2)$\\*
$\vdots$\\*
$I_x(q_n) V_x + I_y (q_n) V_y = -I_t(q_n)$\linebreak\newline\\
}
where $q_1,q_2,\dots,q_n$ are the pixels around a feature inside the window and $I_x(q_i),I_y(q_i),I_t(q_i)$ are the partial derivatives if the image $I$ with respect to position and time $x,y,$ and $t$

This system of equations can be written in the matrix form:\\*

{\centering
$A = \begin{bmatrix}
I_x(q_1) & I_y(q_1) \\[10pt]
I_x(q_2) & I_y(q_2) \\[10pt]
\vdots  & \vdots  \\[10pt]
I_x(q_n) & I_y(q_n) 
\end{bmatrix},
\quad\quad
v = 
\begin{bmatrix}
V_x\\[10pt]
V_y
\end{bmatrix},
\quad \mbox{and}\quad
b = 
\begin{bmatrix}
-I_t(q_1) \\[10pt]
-I_t(q_2) \\[10pt]
\vdots  \\[10pt]
-I_t(q_n)
\end{bmatrix}
$\linebreak\newline\\*}
This overdetermined system is solved with a compromise solution by the least squares principle, solving the 2x2 system:\\*

{\centering
$A^T A v=A^T b$\linebreak\newline\\*}
Bouguet presents a pyramidal implementation of the Lucase Kanade tracker~\cite{bouguet2001pyramidal}, which is the particular implementation that the Kalman Car Counter uses. If the Lucas-Kanade tracker tracks the features detected in the previous step successfully, we can use those features as data points for our Kalman Filter.

\subsection{Optical Flow Data Clustering}
\label{subsec:optical_flow}

The Lucas-Kande tracker can return many successfully tracked features for a single vehicle. We can leverage this by clustering the tracked features to combine them into a single point. Because we cannot predict how many vehicles will be in a frame, we use a agglomerative hierarchical clustering scheme. We use cophenetic distance $t$ as a criterion for automatic clustering of the data, expecting different vehicle feature clusters to have a large distance between them. Once the data is clustered, the means of each cluster that has at least $n$ elements is assigned to a Kalman Filter.

\subsection{Hungarian Algorithm}
\label{subsec:hungarian_algo}

Once each cluster's mean has been established, we intend to again track each cluster, but this time using a Kalman Filter (described in Section~\ref{subsec:kalman_filter}) in order to be more tolerant to noise, occlusion, and merged clusters. Thus, each cluster must be assigned to a Kalman filter. For each existing Kalman filter, we attempt to assign the nearest cluster to that filter for measurement updates. In order so solve the assignment problem we use the Kuhn-Munkres or, simply, Munkres algorithm~\cite{munkres1957algorithms}. It solves a cost matrix where $a1$ would be the distance from a cluster mean $a$ to a Kalman Filter's next prediction $1$:\\*

{\centering
$\begin{bmatrix}
a1 & a2 & a3 & a4\\
b1 & b2 & b3 & b4\\
c1 & c2 & c3 & c4\\
d1 & d2 & d3 & d4\end{bmatrix}$\linebreak\newline\\*}
Solving this cost matrix for the minimum cost produces assignments for each cluster. If the algorithm assigns a cluster to a Kalman filter, it is used as a measurement update for that Kalman filter for the frame. Note that this matrix can be rectangular; there could be more clusters than Kalman filters or more Kalman filters than clusters. If there are more Kalman filters than clusters, Kalman filters that do not get an assignment are marked as "Lost" and do not receive a measurement update. Lost Kalman filters accumulate a Loss Counter each subsequent frame they are lost in until they are either deleted or are again assigned to a cluster.  On the other hand, if there are more clusters than Kalman Filters, a new Kalman filter is created for each new cluster, instantiated with initial position equal to the cluster mean. \justin{You say Kalman filter a lot - maybe shorten to just filter sometimes.}

\subsection{Kalman Filter}
\label{subsec:kalman_filter}

The final step solves a practical problem: even with all the previous steps, our measurements, the mean value of each cluster, are still somewhat noisy measurements of the vehicles location in the video. \justin{Wicked comma splice - I'm not even sure what you mean here.} In order to better track the vehicles, we pass the measurements through a Kalman filter. The filter allows us to track vehicles even if vehicles' measurements are noisy, vehicles are temporarily occluded, or vehicles' clusters merge.

The Kalman filter requires several matrices, the most important of which is the next state function. This Kalman filter will model the motion of the vehicles using a simple system $F$ of $(x,y)$ position and velocity. \\*

{\centering
$F = \begin{bmatrix}
1 & 0 & dt & 0\\
0 & 1 & 0 & dt\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1\end{bmatrix}$\linebreak\newline\\*}
Read in simple English, this matrix means that the next state's position should be estimated using the prior position and velocity multiplied by the change in time. The change in time is set to the number of seconds between each frame of the video. For example, in a 30 frames-per-second video, $dt$ would be .5 seconds.
Each Kalman filter will have it's initial state simply set to the mean of the cluster $(x,y)$ that created it with no initial velocity, that is $V_x = 0$ and $V_y = 0$. \justin{What are you talking about after this...?}\\*

{\centering
$X = \begin{bmatrix}
x \\
y \\
0 \\
0 \end{bmatrix}$\linebreak\newline\\*}
our measurement update function will be\\*

{\centering
$H = \begin{bmatrix}
1 & 0 \\
0 & 1 \\
0 & 0 \\
0 & 0 \end{bmatrix}$\linebreak\newline\\*}
Since we can measure $x$ and $y$ but not $V_x$ or $V_y$ the uncertainty for the velocity will be set very high, while the uncertainty for position will be set relatively low.\\*

{\centering
$R = \begin{bmatrix}
 1 & 0 & 0 & 0\\
 0 & 1 & 0 & 0\\
 0 & 0 & 1000 & 0\\
 0 & 0 & 0 & 1000\end{bmatrix}$\linebreak\newline\\*}

The Kalman filter performs prediction step and calculates the posterior position $X'$:\\*

{\centering
$X' = FX+u$\linebreak\newline\\*}
and it updates uncertainty by:\\*

{\centering
$P' = F \cdot P \cdot F^T$\linebreak\newline\\*}
Similarly, after each prediction step, a measurement update step must be performed with a new measurement $Z$.\\*

{\centering
$Y = Z - H \cdot X$\\*
 $S = H \cdot P \cdot H^T + R$\\*
 $K = P \cdot H^T \cdot S^{-1}$\\*
 $X' = X + (K\cdot Y)$\\*
 $P' = (I - K \cdot H) \cdot P $\linebreak\newline\\*}
 With these two steps iterating every frame, we track each vehicle's starting location to ending location. With the tracked vehicle starting and ending positions in hand, we can count vehicles entering the scene and leaving the scene.
 
\section{Technical Specifications}
\label{sec:technical_specs}

The Kalman Car Tracker has been implemented in the Python programming language. This implementation uses several technologies to accomplish it's task. The foremost is \texttt{OpenCV} (Open Source Computer Vision Library), an open source computer vision and machine learning software library. It contains many optimized and state-of-the art algorithms of use to this project with Python bindings. In particular, the background subtraction, Shi-Tomasi corner detection, Lucas-Kanade optical flow tracking, and Kalman filteings all come from the \texttt{OpenCV} library. The hierarchical data clustering algorithm comes from another powerful Python library known as \texttt{SciPy}. Munkres linear assignment comes from a Python library by Lars Buitinck. \justin{I'd add links or citations to these libraries.}

To test this method, a dataset was captured with a cellphone camera on a highway overpass. A video was recorded from the center of the overpass overlooking the freeway at a resolution of 1080p for three minutes. The overpass vibrated, introducing much noise for our particular background subtraction method. In addition, the camera was held in hand; no tripod or other stabilization was used to record video.

The video processing took approximately 15 minutes for 3 minutes of video on a Intel i7 960 CPU @ 3.20 GHz.



\section{Analysis of Results}
\label{sec:analysis}

In the first half of the sample video on the left (oncoming) lanes of traffic, $24/35$ , or about 68\%, of vehicles were successfully tracked. Our definition of successfully tracked is that Kalman filter tracking the car was assigned for at least the last 6 frames of the car being in the image. Having the car successfully tracked when it leaves the frame would be sufficient to count the car as having flowed under the overpass.  While clearly there is room for improvement, this shows the method implemented in this tool can successfully track vehicles and perform the counting task. The parameters for various methods were not optimized, and the tool is far from complete, but these preliminary results seem promising. Perhaps with optimization and refinement this method could be used as envisioned to enabled simple unattended capture of traffic data. \justin{This could use some tables and graphs to drive the point home.}


\section{Conclusion}
\label{sec:conclusion}

In this paper, we present a method for collecting traffic data using a simple camera and computer vision processing, even in the presence of occlusion and . The method needs refinement, but can successfully track vehicles. This method seems to have trouble differentiating between clusters of tracked optical flows when they are tightly packed, which could prove a large problem for dense traffic flows. This problem might be solved with a better camera perspective, but the best camera perspectives, such as top down, make the detection process much more trivial and come with disadvantages similar to those provided in the introduction: they are costly and hard to set up. Exploring other options for clustering might help alleviate this issue. \justin{Be more positive about your results - they're good. State that further refinements are left to future research, don't say your methodology has a problem - the "other options" portion should also be stated as future research. Future research will explore the benefits of blahblah which may further increase the success rate of our approach.}

\nocite{*}
\bibliographystyle{plain}
\bibliography{KalmanBib}
\end{document}
